{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "640325f8",
   "metadata": {},
   "source": [
    "# Monte Carlo Simulations\n",
    "### Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "835b7156",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################\n",
    "##########################################################################################################################\n",
    "import os\n",
    "import pyreadr\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from scipy.linalg import solve\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt \n",
    "import itertools\n",
    "import concurrent.futures\n",
    "import matplotlib.colors as mcolors\n",
    "from memory_profiler import profile\n",
    "#########################################################################################################################\n",
    "# Set working directory\n",
    "os.chdir('C:\\\\Users\\\\Elkanah\\\\Desktop\\\\Elkanah\\\\Spatiotemporal_AR_Model_LASSO')\n",
    "##########################################################################################################################\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78abd711",
   "metadata": {},
   "source": [
    "# Define basic functions\n",
    "1.  Simulate data which returns the beta,phi,and Queens contiguity matrix\n",
    "2.  LL which returns the log likelihood value\n",
    "3. Constraint function which ensures W is row standardized\n",
    "4.  Cross validation which performs cross validations and selects the best combination of lambda for which the average rmse across the folds is smallest\n",
    "5.  plot lambda graphs which plots the average rmse vs each of the lambda values\n",
    "6. simulate and optimise which performs the entire simulation and returns the optimised values together withthe RMSE of the estimations and the computation time\n",
    "7.  print_and_return_parameter_summary: Analyses the simulation results and plots the estimated weights matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd0666c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for n = 4 spatial units and 50 Timepoints\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elkanah\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:404: RuntimeWarning: Values in x were outside bounds during a minimize step, clipping to bounds\n",
      "  warnings.warn(\"Values in x were outside bounds during a \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication 1 for 50 timepoints ended in 7.1998 hours with an RMSE of 3.596051 and penalties (0.0, 0.0, 1.0)\n",
      "Results for n = 4 spatial units and 100 Timepoints\n",
      "\n",
      "Replication 1 for 100 timepoints ended in 13.5336 hours with an RMSE of 4.390786 and penalties (0.0, 1.0, 1.0)\n",
      "Results for n = 4 spatial units and 200 Timepoints\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################################\n",
    "########################################################################################################################\n",
    "#Parameter initialization\n",
    "n = 4\n",
    "beta = np.array([3, 0, 2])\n",
    "k = 3\n",
    "phi = np.array([0] * int(n * 0.25) + [0.3] * (n - int(n * 0.25)))\n",
    "rho = 0.6\n",
    "\n",
    "# Load data\n",
    "WM = pyreadr.read_r(f'WM{n}.RDA')\n",
    "# Convert WM to a NumPy array\n",
    "WM = np.array(list(WM.values())).reshape((n, n))\n",
    "\n",
    "parameters = np.concatenate((beta, phi, rho * WM[np.triu_indices(WM.shape[0], k=1)], rho * WM[np.tril_indices(WM.shape[0], k=-1)],[1], [np.nan,np.nan,np.nan,np.nan,np.nan]))\n",
    "###################################################################################################################\n",
    "#########################################################################################################################\n",
    "# Define the Log-Likelihood function\n",
    "def LL(parameters, Y, X, n, k, Time, lambda1, lambda2, lambda3):\n",
    "    # Extract the parameters\n",
    "    beta = parameters[:k]\n",
    "    phi = parameters[k:k+n]\n",
    "    W = np.zeros((n, n))\n",
    "    W[np.triu_indices(n, k=1)] = parameters[int(k+n):int(k+n+0.5*n*(n-1))]\n",
    "    W[np.tril_indices(n, k=-1)] = parameters[int(k+n+0.5*n*(n-1)):int(k+n+n*(n-1))]\n",
    "    sigma2_eps = parameters[int(k+n+n*(n-1))]\n",
    "\n",
    "    # Calculate sum of squares\n",
    "    residuals_est = np.zeros(Time - 1)\n",
    "    for t in range(1, Time):\n",
    "        u_t = Y[:, t] - W @ Y[:, t] - X[:, t] @ beta - phi * Y[:, t-1]\n",
    "        residuals_est[t-1] = np.sum(u_t**2 / sigma2_eps)\n",
    "\n",
    "    sum_of_squares = np.sum(residuals_est)\n",
    "\n",
    "    # Calculate log-likelihood\n",
    "    Constant = -0.5 * (Time - 1) * (np.log(2 * np.pi) + np.sum(n * np.log(sigma2_eps))) + (Time - 1) * np.linalg.slogdet(np.eye(n) - W)[1]\n",
    "    LogLik = Constant - (0.5 * sum_of_squares) - (lambda3 * np.sum(np.abs(W)) + lambda2 * np.sum(np.abs(phi)) + lambda1 * np.sum(np.abs(beta)))\n",
    "\n",
    "    return -LogLik\n",
    "##########################################################################################################################\n",
    "##########################################################################################################################\n",
    "# Constraint function for W\n",
    "def constraint_func(param, n, k):\n",
    "    W = np.zeros((n, n))\n",
    "    W[np.triu_indices(n, k=1)] = param[int(k+n):int(k+n+0.5*n*(n-1))]\n",
    "    W[np.tril_indices(n, k=-1)] = param[int(k+n+0.5*n*(n-1)):int(k+n+n*(n-1))]\n",
    "    row_sums = np.sum(W, axis=1)\n",
    "    return 1 - row_sums  # Constraint: row_sums <= 1\n",
    "\n",
    "##########################################################################################################################\n",
    "##########################################################################################################################\n",
    "# Function to perform cross-validation for all lambda combinations\n",
    "def cross_validate_lambda_combination(X, Y, n, k, Time, param, bounds, num_folds=5):\n",
    "    lambda_values1 = np.concatenate(([0], np.logspace(-1, 0, 10)))\n",
    "    lambda_values2 = np.concatenate(([0], np.logspace(-1, 0, 10)))\n",
    "    lambda_values3 = np.concatenate(([0], np.logspace(-1, 0, 10)))\n",
    "\n",
    "    # Create a list of lambda combinations\n",
    "    lambda_combinations = np.array(list(itertools.product(lambda_values1, lambda_values2, lambda_values3)))\n",
    "\n",
    "    Av_RMSE = np.zeros((len(lambda_values1), len(lambda_values2), len(lambda_values3)))  # Array to store average RMSE values for each lambda combination\n",
    "\n",
    "    def cross_validate_lambda(lambdas):\n",
    "        folds_rmse_list = []\n",
    "\n",
    "        def optimize_fold(param, lambdas, Y_train, X_train, n, k, train_index, bounds):\n",
    "            result = minimize(LL, param, args=(Y_train, X_train, n, k, train_index, lambdas[0], lambdas[1], lambdas[2]),\n",
    "                              method='SLSQP', bounds=bounds, constraints={'type': 'ineq', 'fun': lambda x: constraint_func(x, n, k)})\n",
    "            return result\n",
    "\n",
    "        # Iterate over the folds\n",
    "        with concurrent.futures.ThreadPoolExecutor() as fold_executor:\n",
    "            fold_results = []\n",
    "\n",
    "            for fold in range(num_folds):\n",
    "                test_indices = np.arange(fold, Time, num_folds)\n",
    "                train_indices = np.delete(np.arange(Time), test_indices)\n",
    "                X_train = X[:, train_indices]\n",
    "                Y_train = Y[:, train_indices]\n",
    "                X_test = X[:, test_indices]\n",
    "                Y_test = Y[:, test_indices]\n",
    "\n",
    "                result = fold_executor.submit(optimize_fold, param, lambdas, Y_train, X_train, n, k, len(train_indices), bounds)\n",
    "                fold_results.append(result)\n",
    "\n",
    "            concurrent.futures.wait(fold_results)\n",
    "\n",
    "            for result in fold_results:\n",
    "                betas_opt = result.result().x[:k]\n",
    "                phis_opt = result.result().x[k:k + n]\n",
    "                W_opt = np.zeros((n, n))\n",
    "                W_opt[np.triu_indices(n, k=1)] = result.result().x[int(k + n):int(k + n + 0.5 * n * (n - 1))]\n",
    "                W_opt[np.tril_indices(n, k=-1)] = result.result().x[int(k + n + 0.5 * n * (n - 1)):int(k + n + n * (n - 1))]\n",
    "\n",
    "                Y_pred = np.zeros((n, len(test_indices)))\n",
    "                Y_pred[:, 0] = X_test[:, 0] @ betas_opt + W_opt @ Y_train[:, -1]\n",
    "\n",
    "                for t in range(1, len(test_indices)):\n",
    "                    Y_pred[:, t] = X_test[:, t] @ betas_opt + phis_opt * Y_pred[:, t - 1] + W_opt @ Y_pred[:, t]\n",
    "\n",
    "                rmse = np.sqrt(np.mean((Y_pred - Y_test) ** 2))\n",
    "                folds_rmse_list.append(rmse)\n",
    "\n",
    "        # Calculate the average RMSE from the list of fold RMSE values\n",
    "        avg_rmse = np.mean(folds_rmse_list)\n",
    "        return avg_rmse\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as lambda_executor:\n",
    "        # Create tasks for each lambda combination and submit them concurrently\n",
    "        lambda_results = [\n",
    "            lambda_executor.submit(cross_validate_lambda, lambdas)\n",
    "            for lambdas in lambda_combinations\n",
    "        ]\n",
    "\n",
    "        concurrent.futures.wait(lambda_results)\n",
    "\n",
    "        for i, lambdas in enumerate(lambda_combinations):\n",
    "            lambda_result = lambda_results[i].result()\n",
    "            lambda1, lambda2, lambda3 = lambdas\n",
    "            ind_lambda1 = np.where(lambda_values1 == lambda1)[0][0]\n",
    "            ind_lambda2 = np.where(lambda_values2 == lambda2)[0][0]\n",
    "            ind_lambda3 = np.where(lambda_values3 == lambda3)[0][0]\n",
    "            Av_RMSE[ind_lambda1, ind_lambda2, ind_lambda3] = lambda_result\n",
    "\n",
    "    return Av_RMSE, lambda_combinations, lambda_values1, lambda_values2, lambda_values3\n",
    "##########################################################################################################################\n",
    "##########################################################################################################################\n",
    "# Function for replication simulation\n",
    "def replication_simulation(replication_id, Time):\n",
    "    np.random.seed(replication_id)\n",
    "    start_time = time.time()\n",
    "    #print(f'Simulation {replication_id + 1} has started')\n",
    "    Time = Time\n",
    "    XVar = np.random.normal(0, 1, size=(n, Time + 100, k))\n",
    "    eps = np.random.normal(size=(n, Time + 100))\n",
    "    Yo = np.random.normal(0, 1, size=n)\n",
    "    A_I = np.eye(n) - rho * WM\n",
    "    A = np.linalg.inv(A_I)\n",
    "    YVar = np.zeros((n, Time + 100))\n",
    "    \n",
    "    for t in range(1, Time + 100):\n",
    "        if t == 1:\n",
    "            YVar[:, t] = np.dot(A, (np.dot(XVar[:, t, :], beta) + phi * Yo + eps[:, t]))\n",
    "        else:\n",
    "            YVar[:, t] = np.dot(A, (np.dot(XVar[:, t, :], beta) + phi * YVar[:, t-1] + eps[:, t]))\n",
    "\n",
    "    Y = YVar[:, 100:]\n",
    "    X = XVar[:, 100:, :]\n",
    "    param = np.concatenate((np.ones(k), np.repeat(0.1, n), np.repeat(0.001, int(n*(n-1))), [1]))\n",
    "    bounds = [(-1, 5)] * k + [(0, 1)] * n + [(0, 1)] * int(n * (n - 1)) + [(0.0000000000001, np.inf)]\n",
    "\n",
    "    #############################################################################################################\n",
    "    # Calculate average RMSE values for lambda combinations\n",
    "    Av_RMSE, lambda_combinations, lambda_values1, lambda_values2, lambda_values3 = cross_validate_lambda_combination(X, Y, n, k, Time, param, bounds)\n",
    "    #print('The Average RMSE is \\n', Av_RMSE)\n",
    "    \n",
    "    # Find the minimum average RMSE value and corresponding lambda combination\n",
    "    min_avg_rmse = np.min(Av_RMSE)\n",
    "    #best_lambda_combination = lambda_combinations[np.argmin(Av_RMSE)]\n",
    "    #lambda1_opt, lambda2_opt, lambda3_opt = best_lambda_combination\n",
    "    lambda1_opt, lambda2_opt, lambda3_opt = lambda_combinations[np.argmin(Av_RMSE)]\n",
    "    ######################################################################################################\n",
    "    result = minimize(LL, param, args=(Y, X, n, k, Time, lambda1_opt, lambda2_opt, lambda3_opt), method='SLSQP', bounds=bounds, constraints={'type': 'ineq', 'fun': lambda x: constraint_func(x, n, k)})\n",
    "    parameters_opt = result.x\n",
    "\n",
    "    betas_opt = parameters_opt[:k]\n",
    "    phis_opt = parameters_opt[k:k+n]\n",
    "    W_opt = np.zeros((n, n))\n",
    "    W_opt[np.triu_indices(n, k=1)] = parameters_opt[int(k + n):int(k + n + 0.5 * n * (n - 1))]\n",
    "    W_opt[np.tril_indices(n, k=-1)] = parameters_opt[int(k + n + 0.5 * n * (n - 1)):int(k + n + n * (n - 1))]\n",
    "\n",
    "    Y_pred = np.zeros((n, Time))\n",
    "    Y_pred[:, 0] = X[:, 0] @ betas_opt + W_opt @ Y_pred[:, 0]\n",
    "\n",
    "    for t in range(1, Time):\n",
    "        Y_pred[:, t] = X[:, t] @ betas_opt + phis_opt * Y_pred[:, t - 1] + W_opt @ Y_pred[:, t]\n",
    "\n",
    "    rmse_est = np.sqrt(np.mean((Y_pred - Y)**2))\n",
    "    ##########################################################################################################################\n",
    "    end_time = time.time()\n",
    "    timetaken = (end_time - start_time) / 3600\n",
    "    print(f'Replication {replication_id + 1} for {Time} timepoints ended in {timetaken:.4f} hours with an RMSE of {rmse_est:4f} and penalties {lambda1_opt, lambda2_opt, lambda3_opt}')\n",
    "    return np.concatenate((parameters_opt, [rmse_est, timetaken, lambda1_opt, lambda2_opt, lambda3_opt]))\n",
    "##########################################################################################################################\n",
    "##########################################################################################################################\n",
    "if __name__ == \"__main__\":\n",
    "    num_replications = 1\n",
    "    time_points = [50, 100, 200]  # Define the temporal resolution\n",
    "   \n",
    "    Simul_results = []  # Create an empty list to store results\n",
    "\n",
    "    for Time in time_points:\n",
    "        print(f\"Results for n = 4 spatial units and {Time} Timepoints\\n\")\n",
    "        results_for_time = []  # Create a list to store results for the current time point\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(replication_simulation, i, Time) for i in range(num_replications)]\n",
    "\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                if future.result() is not None:\n",
    "                    results_for_time.append(future.result())  # Append results for the current time point\n",
    "\n",
    "        # Append the results for the current time point to the overall results list\n",
    "        Simul_results.append(results_for_time)\n",
    "    np.save('results_spatialunits.npy', Simul_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2093df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Simul_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fdaa68",
   "metadata": {},
   "source": [
    "# Analysis of the Simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the NumPy array from the binary file and reshape\n",
    "#Simul_results = np.load('simul4_results.npy')\n",
    "\n",
    "# Convert the list to a NumPy array\n",
    "Simul_results = np.array(Simul_results)\n",
    "Simul_results = Simul_results.reshape(3, 1, 25)\n",
    "####################################################################\n",
    "# Define the timepoints\n",
    "times = [50, 100, 200]\n",
    "\n",
    "def print_and_return_parameter_summary(simulations,num_replications):\n",
    "    import matplotlib.colors as mcolors\n",
    "\n",
    "    # Create an array to store estimated parameters for all time points\n",
    "    est_parameters = []\n",
    "\n",
    "    # Create a list to store weight matrices for all time points\n",
    "    weight_matrices = []\n",
    "\n",
    "    for i, Time in enumerate(times):\n",
    "        from tabulate import tabulate\n",
    "        # Get simulation results for the current time point\n",
    "        Simul_results = simulations[i,:, :] #simulations[:, i, :] #simulations[:, :, i]\n",
    "        \n",
    "        # Convert simulation results to a DataFrame\n",
    "        results_df = pd.DataFrame(Simul_results)\n",
    "        \n",
    "        colnames = ([\"beta_\" + str(i) for i in range(1, k+1)] +\n",
    "                    [\"phi_\" + str(i) for i in range(1, n+1)] +\n",
    "                    [\"W_\" + str(i) for i in range(1, int(n*(n-1))+1)] +\n",
    "                    [\"sigma\"] + [\"RMSE\"] + [\"time\"] + [\"Lambda1\"]  + [\"Lambda2\"] + [\"Lambda3\"])\n",
    "        results_df.columns = colnames\n",
    "        results_df[\"Replication\"] = np.arange(1, num_replications+1)\n",
    "        results_df = results_df.reindex(columns=[\"Replication\"] + colnames)\n",
    "        \n",
    "        ##################################################################\n",
    "        ####################################################################\n",
    "\n",
    "        # Long format data\n",
    "        data = pd.melt(results_df, id_vars=[\"Replication\"], var_name=\"Param\", value_name=\"Estimate\")\n",
    "        data['true_param'] = np.repeat(parameters, data['Replication'].nunique())  # Add true parameter values to the data\n",
    "        data['Bias'] = data['Estimate'] - data['true_param']  # Calculate the bias for each parameter\n",
    "        data['Squared Error'] = (data['Estimate'] - data['true_param']) ** 2\n",
    "\n",
    "        results_summary = pd.DataFrame({\n",
    "            'Estimate': data.groupby('Param')['Estimate'].mean().round(4),\n",
    "            'True Param': data.groupby('Param')['true_param'].first(),\n",
    "            'Bias': data.groupby('Param')['Bias'].mean(),\n",
    "            'RBias': data.groupby('Param')['Bias'].mean() / data.groupby('Param')['true_param'].mean(),\n",
    "            'RMSE': np.sqrt(data.groupby('Param')['Squared Error'].mean()).round(4)\n",
    "        })\n",
    "        #Display the average value of parameters across replications together with their rmse and bias\n",
    "        results_summary = results_summary.reindex(colnames)\n",
    "\n",
    "        # Append estimated parameters for this time point to the list\n",
    "        est_parameters.append(results_summary['Estimate'].values)\n",
    "        #print(f\"The estimated parameters for {Time} points are {est_parameters}\")\n",
    "\n",
    "        # Calculate weights matrix W\n",
    "        W = np.zeros((n, n))\n",
    "        W[np.triu_indices(n, k=1)] = est_parameters[i][int(k+n):int(k+n+0.5*n*(n-1))]\n",
    "        W[np.tril_indices(n, k=-1)] = est_parameters[i][int(k+n+0.5*n*(n-1)):int(k+n+n*(n-1))]\n",
    "\n",
    "        # Append the weight matrix to the list\n",
    "        weight_matrices.append(W)\n",
    "\n",
    "        # Print the results for this time point with bold and big text\n",
    "        print(f\"\\n\\033[1m\\033[91m\\033[4m{'Results for'}\\033[0m {n} \\033[1m\\033[91m\\033[4m{'spatial units'}\\033[0m and {Time} \\033[1m\\033[91m\\033[4m{'Timepoints'}\\033[0m \\n\")\n",
    "        print(\"........................................................................\")\n",
    "        #print(\"The average parameter values across replications together with bias and RMSE\")\n",
    "        print(results_summary.head(25))\n",
    "        print(\"........................................................................\")\n",
    "        \n",
    "        # Calculate averages\n",
    "        Est_Beta = results_summary.loc[results_summary.index.str.startswith(\"beta\"), [\"Bias\",  \"RMSE\"]].mean().round(4)\n",
    "        Est_Phi = results_summary.loc[results_summary.index.str.startswith(\"phi\"), [\"Bias\",  \"RMSE\"]].mean().round(4)\n",
    "        Est_W_Full = results_summary.loc[results_summary.index.str.startswith(\"W\"), [\"Bias\", \"RMSE\"]].mean().round(4)\n",
    "        zero_weights = results_summary.loc[results_summary.index.str.startswith(\"W\")].loc[results_summary['True Param'] == 0]\n",
    "        non_zero_weights = results_summary.loc[results_summary.index.str.startswith(\"W\")].loc[results_summary['True Param'] != 0]\n",
    "        Est_W_Zero = zero_weights[[\"Bias\", \"RMSE\"]].mean().round(4)\n",
    "        Est_W_NonZero = non_zero_weights[[\"Bias\", \"RMSE\"]].mean().round(4)\n",
    "        Est_Sigma = results_summary.loc[results_summary.index.str.startswith(\"sigma\"), [\"Bias\", \"RMSE\"]].mean().round(4)\n",
    "        Average_time = results_summary.loc[results_summary.index.str.startswith(\"time\"), \"Estimate\"].mean()\n",
    "        Average_RMSE = results_summary.loc[results_summary.index.str.startswith(\"RMSE\"), \"Estimate\"].mean()\n",
    "        \n",
    "        # Parameter results table\n",
    "        Parameter_results = pd.DataFrame({\n",
    "        'Parameter': ['Beta', 'Phi', 'W(Full)', 'W(zero)', 'W(non zero)', 'Sigma', 'Average time', 'Estimation_RMSE'],\n",
    "        'Bias': [Est_Beta['Bias'], Est_Phi['Bias'], Est_W_Full['Bias'], Est_W_Zero['Bias'], Est_W_NonZero['Bias'], Est_Sigma['Bias'], Average_time, Average_RMSE],\n",
    "        'RMSE': [Est_Beta['RMSE'], Est_Phi['RMSE'], Est_W_Full['RMSE'], Est_W_Zero['RMSE'], Est_W_NonZero['RMSE'], Est_Sigma['RMSE'], np.nan, np.nan]\n",
    "    })\n",
    "        \n",
    "        # Print the percentages\n",
    "        print(f\"\\n The parameter summary statistics for {n} Spatial units and {Time} timepoints\")\n",
    "        print(tabulate(Parameter_results, headers='keys', tablefmt='pretty', showindex=False))\n",
    "        #print(Parameter_results.head(8))\n",
    "        ################################################################\n",
    "        ###################################################################\n",
    "        \n",
    "    #############################################################################################################\n",
    "    #############################################################################################################\n",
    "    # Set up the figure and colormap for weight matrices\n",
    "    fig, axs = plt.subplots(1, len(times) + 1, figsize=(15, 4))\n",
    "    titles = [\"True Weights\"] + [f\"Est_Weights (T={t})\" for t in times]\n",
    "    images = [rho * WM] + weight_matrices\n",
    "\n",
    "    # Calculate colormap bounds\n",
    "    vmin = min(np.min(image) for image in images)\n",
    "    vmax = max(np.max(image) for image in images)\n",
    "\n",
    "    # Create a custom grayscale colormap\n",
    "    colors = [(1, 1, 1), (0.2, 0.2, 0.2)]\n",
    "    cmap_gray = mcolors.LinearSegmentedColormap.from_list('custom_gray', colors)\n",
    "\n",
    "    # Plot and set up the figure for weight matrices\n",
    "    for ax, title, image in zip(axs, titles, images):\n",
    "        im = ax.imshow(image, cmap=cmap_gray, origin='upper', vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(title)\n",
    "        ax.axis(\"off\")\n",
    "        cbar = plt.colorbar(im, ax=ax, orientation='vertical', fraction=0.05)\n",
    "\n",
    "    plt.suptitle(f\"Weights Matrices for n={n} spatial units\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()  # Close the figure to free up resources\n",
    "    ######################################################################################################################\n",
    "print_and_return_parameter_summary(Simul_results,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3257897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Simul_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a17a91a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
